{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d0e0ff",
   "metadata": {},
   "source": [
    "## Defensive Team Classifiers Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "185b9267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "# uncomment once you paste your myclassifiers.py into mysklearn package\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import (MyKNeighborsClassifier, MyDummyClassifier, \n",
    "                                     MyNaiveBayesClassifier, MyDecisionTreeClassifier,\n",
    "                                     MyRandomForestClassifier)\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e36520f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3412 samples using MyPyTable.\n",
      "Features: ['drb_per_game', 'stl_per_game', 'blk_per_game', 'stl_percent', 'blk_percent', 'dws', 'dbpm', 'drb_percent']\n",
      "Sample Raw: [2.0, 0.9, 0.3, 1.4, 0.6, 1.5, -1.3, 7.1]\n",
      "Sample Norm: [0.16260162601626016, 0.24324324324324323, 0.06, 0.08, 0.009538950715421303, 0.19999999999999998, 0.5548098434004474, 0.071]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "table = MyPyTable()\n",
    "table.load_from_file(\"data/Balanced_Defensive_Team_Data_Sampled.csv\")\n",
    "\n",
    "\n",
    "# 2. Define the features you want to use\n",
    "feature_names = [\n",
    "    \"drb_per_game\", \"stl_per_game\", \"blk_per_game\", \"stl_percent\", \"blk_percent\",\n",
    "    \"dws\", \"dbpm\", \"drb_percent\"\n",
    "]\n",
    "\n",
    "# This replaces any \"NA\" strings with the column's average, making the column fully numeric.\n",
    "for col in feature_names:\n",
    "    table.replace_missing_values_with_column_average(col)\n",
    "\n",
    "# 4. Extract X (Features)\n",
    "# We find the index of each desired column, then grab those values from table.data\n",
    "col_indices = [table.column_names.index(name) for name in feature_names]\n",
    "\n",
    "X = []\n",
    "for row in table.data:\n",
    "    # Create a new row containing only the selected features\n",
    "    sample = [row[i] for i in col_indices]\n",
    "    X.append(sample)\n",
    "\n",
    "# 5. Extract y (Target)\n",
    "y_col = table.get_column(\"voted\")\n",
    "# Ensure y is integer (0/1) not float (0.0/1.0)\n",
    "y = [int(val) for val in y_col]\n",
    "\n",
    "# 6. Preprocessing\n",
    "X_normalized = myutils.normalize_table(X)\n",
    "#X_discretized = discretize_data(X, n_bins=10)\n",
    "\n",
    "print(f\"Loaded {len(X)} samples using MyPyTable.\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "print(f\"Sample Raw: {X[0]}\")\n",
    "print(f\"Sample Norm: {X_normalized[0]}\")\n",
    "#print(f\"Sample Disc: {X_discretized[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "170bf657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating Dummy Classifier ---\n",
      "Accuracy:  0.481\n",
      "Precision: 0.140\n",
      "Recall:    0.300\n",
      "F1 Score:  0.191\n",
      "Confusion Matrix (0=No, 1=Yes):\n",
      "     Pred 0   Pred 1\n",
      "True 0:  1160      546\n",
      "True 1:  1226      480\n",
      "\n",
      "\n",
      "--- Evaluating kNN (k=5) ---\n",
      "Accuracy:  0.888\n",
      "Precision: 0.858\n",
      "Recall:    0.929\n",
      "F1 Score:  0.892\n",
      "Confusion Matrix (0=No, 1=Yes):\n",
      "     Pred 0   Pred 1\n",
      "True 0:  1444      262\n",
      "True 1:  121      1585\n",
      "\n",
      "\n",
      "--- Evaluating Decision Tree (D=5) ---\n",
      "Accuracy:  0.864\n",
      "Precision: 0.826\n",
      "Recall:    0.923\n",
      "F1 Score:  0.871\n",
      "Confusion Matrix (0=No, 1=Yes):\n",
      "     Pred 0   Pred 1\n",
      "True 0:  1374      332\n",
      "True 1:  133      1573\n",
      "\n",
      "\n",
      "--- Evaluating Random Forest (20T, D=5, max_f=3) ---\n",
      "Accuracy:  0.880\n",
      "Precision: 0.836\n",
      "Recall:    0.946\n",
      "F1 Score:  0.887\n",
      "Confusion Matrix (0=No, 1=Yes):\n",
      "     Pred 0   Pred 1\n",
      "True 0:  1389      317\n",
      "True 1:  93      1613\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Classifier Configurations (not instances - we'll create fresh instances per fold)\n",
    "classifier_configs = [\n",
    "    (\"Dummy Classifier\", MyDummyClassifier, {}, \"X_normalized\"),\n",
    "    (\"kNN (k=5)\", MyKNeighborsClassifier, {\"n_neighbors\": 5}, \"X_normalized\"),\n",
    "    (\"Decision Tree (D=5)\", MyDecisionTreeClassifier, {\"max_depth\": 5}, \"X_normalized\"),\n",
    "    (\"Random Forest (20T, D=5, max_f=3)\", MyRandomForestClassifier, {\"n_trees\": 20, \"max_depth\": 5, \"max_features\": 3}, \"X_normalized\")\n",
    "]\n",
    "\n",
    "n_splits = 10\n",
    "folds = myevaluation.stratified_kfold_split(X, y, n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for clf_name, clf_class, clf_params, dataset_name in classifier_configs:\n",
    "    print(f\"--- Evaluating {clf_name} ---\")\n",
    "    \n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    \n",
    "    X_dataset = X_normalized  # Use the appropriate dataset\n",
    "    \n",
    "    for train_idx, test_idx in folds:\n",
    "        X_train = [X_dataset[i] for i in train_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        X_test = [X_dataset[i] for i in test_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "\n",
    "        # Create a fresh classifier instance for each fold\n",
    "        clf = clf_class(**clf_params)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        accuracies.append(myevaluation.accuracy_score(y_test, y_pred))\n",
    "        precisions.append(myevaluation.binary_precision_score(y_test, y_pred, pos_label=1))\n",
    "        recalls.append(myevaluation.binary_recall_score(y_test, y_pred, pos_label=1))\n",
    "        f1_scores.append(myevaluation.binary_f1_score(y_test, y_pred, pos_label=1))\n",
    "        \n",
    "        all_y_true.extend(y_test)\n",
    "        all_y_pred.extend(y_pred)\n",
    "\n",
    "    print(f\"Accuracy:  {sum(accuracies)/len(accuracies):.3f}\")\n",
    "    print(f\"Precision: {sum(precisions)/len(precisions):.3f}\")\n",
    "    print(f\"Recall:    {sum(recalls)/len(recalls):.3f}\")\n",
    "    print(f\"F1 Score:  {sum(f1_scores)/len(f1_scores):.3f}\")\n",
    "    \n",
    "    matrix = myevaluation.confusion_matrix(all_y_true, all_y_pred, labels=[0, 1])\n",
    "    print(\"Confusion Matrix (0=No, 1=Yes):\")\n",
    "    print(f\"     Pred 0   Pred 1\")\n",
    "    print(f\"True 0:  {matrix[0][0]}      {matrix[0][1]}\")\n",
    "    print(f\"True 1:  {matrix[1][0]}      {matrix[1][1]}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
